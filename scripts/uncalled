#!/usr/bin/env python

# MIT License
#
# Copyright (c) 2018 Sam Kovaka <skovaka@gmail.com>
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

#TODO try to improve module names
from uncalled import mapping, index, pafstats, minknow_client, params, sim_utils
import numpy as np
import sys                         
import os
import argparse
import time
import re
import time
import subprocess
import traceback

MAX_SLEEP = 0.01

#TODO: make defaults show up in help text
#maybe move all this argparse stuff into a new module
class ArgFormat(argparse.ArgumentDefaultsHelpFormatter):
    pass


def add_index_opts(p, conf):
    p.add_argument("fasta_filename", type=str, help="FASTA file to index")
    p.add_argument("-o", "--bwa-prefix", default=None, type=str, help="Index output prefix. Will use input fasta filename by default")
    p.add_argument("-s", "--max-sample-dist", default=100, type=int, help="Maximum average sampling distance between reference self-alignments.")
    p.add_argument("--min-samples", default=50000, type=int, help="Minimum number of self-alignments to produce (approximate, due to deterministically random start locations)")
    p.add_argument("--max-samples", default=1000000, type=int, help="Maximum number of self-alignments to produce (approximate, due to deterministically random start locations)")
    p.add_argument("-k", "--kmer-len", default=5, type=int, help="Model k-mer length")
    p.add_argument("-1", "--matchpr1", default=0.6334, type=float, help="Minimum event match probability")
    p.add_argument("-2", "--matchpr2", default=0.9838, type=float, help="Maximum event match probability")
    p.add_argument("-f", "--pathlen-percentile", default=0.05, type=float, help="")
    p.add_argument("-m", "--max-replen", default=100, type=int, help="")
    p.add_argument("--probs", default=None, type=str, help="Find parameters with specified target probabilites (comma separated)")
    p.add_argument("--speeds", default=None, type=str, help="Find parameters with specified speed coefficents (comma separated)")

def add_bwa_opt(p, conf):
    p.add_argument("bwa_prefix", type=str, help="BWA prefix to mapping to. Must be processed by \"uncalled index\".")
    p.add_argument("-p", "--idx-preset", default=conf.idx_preset, type=str, help="Mapping mode")


def add_ru_opts(p, conf):
    #TODO: selectively enrich or deplete refs in index
    p.add_argument("-c", "--max-chunks", default=conf.max_chunks, required=True, type=int, help="Will give up on a read after this many chunks have been processed. Only has effect when --unblock is set")
    p.add_argument("--chunk-time", required=False, type=float, default=1, help="Length of chunks in seconds")

    modes = p.add_mutually_exclusive_group(required=True)
    modes.add_argument("-D", "--deplete", action='store_const', const=mapping.RealtimeMode.DEPLETE, dest='realtime_mode', help="Will eject reads that align to index")
    modes.add_argument("-E", "--enrich", action='store_const',  const=mapping.RealtimeMode.ENRICH, dest='realtime_mode', help="Will eject reads that don't align to index")

    active = p.add_mutually_exclusive_group()
    active.add_argument("--full", action='store_const', const=mapping.ActiveChs.FULL, dest='active_chs', help="Will monitor all pores if set (default)")
    active.add_argument("--even", action='store_const', const=mapping.ActiveChs.EVEN, dest='active_chs', help="Will only monitor even pores if set")
    active.add_argument("--odd", action='store_const', const=mapping.ActiveChs.ODD, dest='active_chs', help="Will only monitor odd pores if set")

def add_sim_opts(p, conf):
    p.add_argument("fast5s", nargs='+', type=str, help="Reads to mapping. Can be a directory which will be recursively searched for all files with the \".fast5\" extension, a text file containing one fast5 filename per line, or a comma-separated list of fast5 file names.")
    p.add_argument("-r", "--recursive", action="store_true")
    p.add_argument("--ctl-seqsum", required=True, type=str, help="")
    p.add_argument("--unc-seqsum", required=True, type=str, help="")
    p.add_argument("--unc-paf", required=True, type=str, help="")
    p.add_argument("--sim-speed", required=False, default=1.0, type=float, help="")

def add_realtime_opts(p, conf):
    p.add_argument('--host', default=conf.host, help='MinKNOW server host.')
    p.add_argument('--port', type=int, default=conf.port, help='MinKNOW server port.')
    p.add_argument('--duration', type=float, default=conf.duration, help='Duration to map real-time run in hours. Should be slightly longer than specified runtime to add wiggle room.')

def add_list_ports_opts(p, conf):
    p.add_argument('--log-dir', default='/var/log/MinKNOW', help='Directory to find MinKNOW log files')

def add_fast5_opts(p, conf):
    p.add_argument("fast5s", nargs='+', type=str, help="Reads to mapping. Can be a directory which will be recursively searched for all files with the \".fast5\" extension, a text file containing one fast5 filename per line, or a comma-separated list of fast5 file names.")
    p.add_argument("-r", "--recursive", action="store_true")

    p.add_argument("-l", "--read-list", default=None, type=str, help="Only map reads listed in this file")
    p.add_argument("-n", "--max-reads", type=int, default=None, help="Maximum number of reads to map")

#TODO get defautls from conf
def add_map_opts(p, conf):
    p.add_argument("-t", "--threads", default=conf.threads, type=int, help="Number of threads to use for mapping")
    p.add_argument("--num-channels", default=conf.num_channels, type=int, help="Number of channels used in sequencing. If provided will use unique mapper for each channel. Useful for streaming normalization simulation.")
    p.add_argument("-e", "--max-events", default=conf.max_events, type=int, help="Will give up on a read after this many events have been processed")

def get_parser(conf):
    parser = argparse.ArgumentParser(description="Rapidly maps raw nanopore signal to DNA references", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    sp = parser.add_subparsers(dest="subcmd")

    index_parser = sp.add_parser("index", help="Calculates reference-specific parameters needed to map to a given a BWA-index.", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    #add_bwa_opt(index_parser)
    add_index_opts(index_parser, conf)

    map_parser = sp.add_parser("map", help="Map fast5 files to a BWA index that has been processed by \"uncalled index\"", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    add_bwa_opt(map_parser, conf)
    add_fast5_opts(map_parser, conf)
    add_map_opts(map_parser, conf)

    rt_parser = sp.add_parser("realtime", help="Perform real-time targeted sequencing", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    add_bwa_opt(rt_parser, conf)
    add_map_opts(rt_parser, conf)
    add_ru_opts(rt_parser, conf)
    add_realtime_opts(rt_parser, conf)

    sim_parser = sp.add_parser("sim", help="Simulate real-time target sequencing", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    add_bwa_opt(sim_parser, conf)
    add_sim_opts(sim_parser, conf)
    add_map_opts(sim_parser, conf)
    add_ru_opts(sim_parser, conf)

    ps_parser = sp.add_parser("pafstats", help="Computes speed and accuracy of UNCALLED mappings. Given an UNCALLED PAF file, will compute mean/median BP mapped per second, number of BP required to map each read, and total number of milliseconds to map each read. Can also optionally compute accuracy with respect to reference alignments, for example output by minimap2.")
    pafstats.add_opts(ps_parser)

    lp_parser = sp.add_parser("list-ports", help="List the port of all MinION devices detected in the current MinKNOW session", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    add_list_ports_opts(lp_parser, conf)

    return parser

def load_args(args, conf):
    for a, v in vars(args).items():
        if v == None:
            #sys.stderr.write("%s IS NONE\n" % a)
            continue

        if (not a.startswith("_")):
            if hasattr(conf, a):
                setattr(conf, a, v)
            #else:
            #    sys.stderr.write("%s\t%s\n" % (a, str(v)))

def index_cmd(args):

    if args.bwa_prefix == None:
        args.bwa_prefix = args.fasta_filename

    bwa_built = True

    for suff in index.BWA_SUFFS:
        if not os.path.exists(args.bwa_prefix + suff):
            bwa_built = False
            break

    if bwa_built:
        sys.stderr.write("Using previously built BWA index.\nNote: to fully re-build the index delete files with the \"%s.*\" prefix.\n" % args.bwa_prefix)
    else:
        mapping.BwaIndex.create(args.fasta_filename, args.bwa_prefix)

    sys.stderr.write("Initializing parameter search\n")
    p = index.IndexParameterizer(args)

    p.add_preset("default", tgt_speed=115)

    if args.probs != None:
        for tgt in args.probs.split(","):
            sys.stderr.write("Writing 'prob_%s' parameters\n" % tgt)
            try:
                p.add_preset("prob_%s" % tgt, tgt_prob=float(tgt))
            except Exception as e:
                sys.stderr.write("Failed to add 'prob_%s'\n" % tgt)

    if args.speeds != None:
        for tgt in args.speeds.split(","):
            sys.stderr.write("Writing 'speed_%s' parameters\n" % tgt)
            try:
                p.add_preset("speed_%s" % tgt, tgt_speed=float(tgt))
            except:
                sys.stderr.write("Failed to add 'speed_%s'\n" % tgt)

    p.write()

    sys.stderr.write("Done\n")

def fast5_path(fname):
    if fname.startswith("#") or not fname.endswith("fast5"):
        return None

    path = os.path.abspath(fname)
    if not os.path.isfile(path):
        sys.stderr.write("Warning: \"%s\" is not a fast5 file.\n")
        return None

    return path

def load_fast5s(fast5s, recursive):
    for path in fast5s:
        path = path.strip()
        isdir = os.path.isdir(path)

        #Recursive directory search 
        if isdir and recursive:
            for root, dirs, files in os.walk(path):
                for fname in files:
                    yield fast5_path(os.path.join(root, fname))

        #Non-recursive directory search 
        elif isdir and not recursive:
            for fname in os.listdir(path):
                yield fast5_path(os.path.join(path, fname))

        #Read fast5 name directly
        elif path.endswith("fast5"):
            yield fast5_path(path)

        #Read fast5 filenames from text file
        else:
            with open(path) as infile:
                for line in infile:
                    yield fast5_path(line.strip())

def assert_exists(fname):
    if not os.path.exists(fname):
        sys.stderr.write("Error: '%s' does not exist\n" % fname)
        sys.exit(1)

def map_cmd(args):
    #conf = mapping.Conf(params.CONF_DEFAULTS)
    conf = mapping.Conf()
    load_args(args, conf)

    assert_exists(params.MODEL_FNAME)
    assert_exists(conf.bwa_prefix + ".bwt")
    assert_exists(conf.bwa_prefix + ".uncl")

    #for fname in open(conf.fast5_list):
    #    assert_exists(fname.strip())

    if len(conf.read_list) > 0:
        assert_exists(conf.read_list)

    sys.stderr.flush()

    mapper = mapping.MapPool(conf)

    sys.stderr.write("Loading fast5s\n")
    for fast5 in load_fast5s(args.fast5s, args.recursive):
        if fast5 != None:
            mapper.add_fast5(fast5)

    sys.stderr.flush()

    sys.stderr.write("Mapping\n")
    sys.stderr.flush()

    n = 0

    try:
        while mapper.running():
            t0 = time.time()
            for p in mapper.update():
                p.print_paf()
                n += 1
            dt = time.time() - t0;
            if dt < MAX_SLEEP:
                time.sleep(MAX_SLEEP - dt);
    except KeyboardInterrupt:
        pass
    
    sys.stderr.write("Finishing\n")
    mapper.stop()

def realtime_cmd(args):

    sim = args.subcmd == "sim"

    #conf = mapping.Conf(params.CONF_DEFAULTS)
    conf = mapping.Conf()
    load_args(args, conf)

    assert_exists(params.MODEL_FNAME)
    assert_exists(conf.bwa_prefix + ".bwt")
    assert_exists(conf.bwa_prefix + ".uncl")

    pool = None
    client = None

    try:
        if sim:
            client = mapping.ClientSim(conf)
            sim_utils.load_sim(client, conf)

            for fast5 in load_fast5s(args.fast5s, args.recursive):
                if fast5 != None:
                    client.add_fast5(fast5)

            client.load_fast5s()

        else:
            if not minknow_client.ru_loaded:
                sys.stderr.write("Error: read_until module not installed. Please install \"read_until_api\" submodule.\n")
                sys.exit(1)
            client = minknow_client.Client(conf.host, conf.port, conf.chunk_time, conf.num_channels)

        if not client.run():
            sys.exit(1)

        deplete = conf.realtime_mode == mapping.RealtimeMode.DEPLETE
        even = conf.active_chs == mapping.ActiveChs.EVEN #TODO: do within mapper

        if not sim:
            raw_type = str(client.signal_dtype)

        pool = mapping.RealtimePool(conf)

        chunk_times = [time.time() for c in range(conf.num_channels)]
        unblocked = [None for c in range(conf.num_channels)]

        #client.log("Processing reads")

        if conf.duration == None or conf.duration == 0:
            end_time = float("inf")
        else:
            end_time = conf.duration*60*60

        while client.is_running:
            t0 = time.time()

            for ch, nm, paf in pool.update():
                t = time.time()-chunk_times[ch-1]
                if paf.is_ended():
                    paf.set_float(mapping.Paf.Tag.ENDED, t)
                    client.stop_receiving_read(ch, nm)

                elif (paf.is_mapped() and deplete) or not (paf.is_mapped() or deplete):

                    if sim or client.should_eject():
                        paf.set_float(mapping.Paf.Tag.EJECT, t)
                        u = client.unblock_read(ch, nm)

                        if sim:
                            paf.set_int(mapping.Paf.Tag.DELAY, u)

                        unblocked[ch-1] = nm
                    else:
                        paf.set_float(mapping.Paf.Tag.IN_SCAN, t)
                        client.stop_receiving_read(ch, nm)

                else:
                    paf.set_float(mapping.Paf.Tag.KEEP, t)
                    client.stop_receiving_read(ch, nm)

                paf.print_paf()

            if sim:
                read_batch = client.get_read_chunks()
                for channel, read in read_batch:
                    if even and channel % 2 == 1:
                        client.stop_receiving_read(channel, read.number)
                    else:
                        if unblocked[channel-1] == read.number:
                            sys.stdout.write("# recieved chunk from %s after unblocking\n" % read.id)
                            continue

                        chunk_times[channel-1] = time.time()
                        pool.add_chunk(read)
       
            else:

                read_batch = client.get_read_chunks(batch_size=client.queue_length)
                for channel, read in read_batch:
                    if even and channel % 2 == 1:
                        client.stop_receiving_read(channel, read.number)
                    else:
                        if unblocked[channel-1] == read.number:
                            sys.stdout.write("# recieved chunk from %s after unblocking\n" % read.id)
                            continue

                        chunk_times[channel-1] = time.time()
                        pool.add_chunk(mapping.Chunk(read.id, 
                                                     channel, 
                                                     read.number,
                                                     read.chunk_start_sample,
                                                     raw_type,
                                                     read.raw_data))


            if client.get_runtime() >= end_time:
                if not sim:
                    client.reset()
                client = None
                break

            dt = time.time() - t0;
            if dt < MAX_SLEEP:
                time.sleep(MAX_SLEEP - dt);

    except KeyboardInterrupt:
        sys.stderr.write("Keyboard interrupt\n")

    except Exception as e:
        sys.stderr.write(traceback.format_exc())

    #client.log("Finished")

    if client != None and not sim:
        client.reset()

    if pool != None:
        pool.stop_all()

def sim_cmd(args):
    sim_utils.load_sim()

#TODO fix
def list_ports_cmd(args):
    log_re = re.compile("^([0-9\-]+ [0-9:]+).+ :.+instance_started.+")
    port_re = re.compile("grpc_port = (\d+)")
    device_re = re.compile("(device_id|instance) = ([^\s,]+)")

    fnames = os.listdir(args.log_dir)
    log_fnames = list(sorted( (f for f in fnames if f.startswith("mk_manager_svc")) ))
    latest_log = os.path.join(args.log_dir, log_fnames[-1])

    for line in open(latest_log):
        lm = log_re.match(line)
        if not lm: continue
        pm = port_re.search(line)
        dm = device_re.search(line)

        if pm is None or dm is None:
            sys.stderr.write("Error: failed to parse \"%s\"\n" % line.strip())
            continue

        timestamp = lm.group(1)
        port = pm.group(1)
        device = dm.group(2)

        sys.stdout.write("%s (%s): %s\n" % (device, timestamp, port))



if __name__ == "__main__":
    
    conf = mapping.Conf()

    parser = get_parser(conf)
    args = parser.parse_args()

    if args.subcmd == "index":
        index_cmd(args)
    elif args.subcmd == "map":
        map_cmd(args)
    elif args.subcmd in {"sim", "realtime"}:
        realtime_cmd(args)
    elif args.subcmd == "list-ports":
        list_ports_cmd(args)
    elif args.subcmd == "pafstats":
        pafstats.run(args)
    else:
        parser.print_help()
        
